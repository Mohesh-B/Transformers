{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMMUehUFxU2aKXk5Pos/lFd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohesh-B/Transformers/blob/main/TransformersUsingKerasAndTensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Layer"
      ],
      "metadata": {
        "id": "frdumDFDm8Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hh1fNXZdknti"
      },
      "outputs": [],
      "source": [
        "class FeedForward(Layer):\n",
        "    def __init__(self, d_ff, d_model, **kwargs):\n",
        "        super(FeedForward, self).__init__(**kwargs)\n",
        "        self.fully_connected1 = Dense(d_ff)  # First fully connected layer\n",
        "        self.fully_connected2 = Dense(d_model)  # Second fully connected layer\n",
        "        self.activation = ReLU()  # ReLU activation layer\n",
        "\n",
        "    def call(self, x):\n",
        "        # The input is passed into the two fully-connected layers, with a ReLU in between\n",
        "        x_fc1 = self.fully_connected1(x)\n",
        "\n",
        "        return self.fully_connected2(self.activation(x_fc1))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AddNormalization(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AddNormalization, self).__init__(**kwargs)\n",
        "        self.layer_norm = LayerNormalization()  # Layer normalization layer\n",
        "\n",
        "\n",
        "    def call(self, x, sublayer_x):\n",
        "        # The sublayer input and output need to be of the same shape to be summed\n",
        "        add = x + sublayer_x\n",
        "\n",
        "        # Apply layer normalization to the sum\n",
        "        return self.layer_norm(add)"
      ],
      "metadata": {
        "id": "1sDmG2cklPOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(Layer):\n",
        "    def __init__(self, h, d_k, d_v, d_model, d_ff, rate, **kwargs):\n",
        "        super(EncoderLayer, self).__init__(**kwargs)\n",
        "        self.multihead_attention = MultiHeadAttention(h, d_k, d_v, d_model)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.add_norm1 = AddNormalization()\n",
        "        self.feed_forward = FeedForward(d_ff, d_model)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "        self.add_norm2 = AddNormalization()\n",
        "\n",
        "    def call(self, x, padding_mask, training):\n",
        "        # Multi-head attention layer\n",
        "        multihead_output = self.multihead_attention(x, x, x, padding_mask)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Add in a dropout layer\n",
        "        multihead_output = self.dropout1(multihead_output, training=training)\n",
        "\n",
        "        # Followed by an Add & Norm layer\n",
        "        addnorm_output = self.add_norm1(x, multihead_output)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Followed by a fully connected layer\n",
        "        feedforward_output = self.feed_forward(addnorm_output)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Add in another dropout layer\n",
        "        feedforward_output = self.dropout2(feedforward_output, training=training)\n",
        "\n",
        "        # Followed by another Add & Norm layer\n",
        "        return self.add_norm2(addnorm_output, feedforward_output)\n"
      ],
      "metadata": {
        "id": "oZ7KRxePlkIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(Layer):\n",
        "    def __init__(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate, **kwargs):\n",
        "        super(Encoder, self).__init__(**kwargs)\n",
        "        self.pos_encoding = PositionEmbeddingFixedWeights(sequence_length, vocab_size, d_model)\n",
        "        self.dropout = Dropout(rate)\n",
        "        self.encoder_layer = [EncoderLayer(h, d_k, d_v, d_model, d_ff, rate) for _ in range(n)]\n",
        "        ...\n",
        "    def call(self, input_sentence, padding_mask, training):\n",
        "        # Generate the positional encoding\n",
        "        pos_encoding_output = self.pos_encoding(input_sentence)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Add in a dropout layer\n",
        "        x = self.dropout(pos_encoding_output, training=training)\n",
        "\n",
        "        # Pass on the positional encoded values to each encoder layer\n",
        "        for i, layer in enumerate(self.encoder_layer):\n",
        "            x = layer(x, padding_mask, training)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "EBHYeB0ulr_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import math, matmul, reshape, shape, transpose, cast, float32\n",
        "from tensorflow.keras.layers import Dense, Layer\n",
        "from keras.backend import softmax\n",
        "\n",
        "# Implementing the Scaled-Dot Product Attention\n",
        "class DotProductAttention(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(DotProductAttention, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, queries, keys, values, d_k, mask=None):\n",
        "        # Scoring the queries against the keys after transposing the latter, and scaling\n",
        "        scores = matmul(queries, keys, transpose_b=True) / math.sqrt(cast(d_k, float32))\n",
        "\n",
        "        # Apply mask to the attention scores\n",
        "        if mask is not None:\n",
        "            scores += -1e9 * mask\n",
        "\n",
        "        # Computing the weights by a softmax operation\n",
        "        weights = softmax(scores)\n",
        "\n",
        "        # Computing the attention by a weighted sum of the value vectors\n",
        "        return matmul(weights, values)\n",
        "\n",
        "# Implementing the Multi-Head Attention\n",
        "class MultiHeadAttention(Layer):\n",
        "    def __init__(self, h, d_k, d_v, d_model, **kwargs):\n",
        "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
        "        self.attention = DotProductAttention()  # Scaled dot product attention\n",
        "        self.heads = h  # Number of attention heads to use\n",
        "        self.d_k = d_k  # Dimensionality of the linearly projected queries and keys\n",
        "        self.d_v = d_v  # Dimensionality of the linearly projected values\n",
        "        self.d_model = d_model  # Dimensionality of the model\n",
        "        self.W_q = Dense(d_k)  # Learned projection matrix for the queries\n",
        "        self.W_k = Dense(d_k)  # Learned projection matrix for the keys\n",
        "        self.W_v = Dense(d_v)  # Learned projection matrix for the values\n",
        "        self.W_o = Dense(d_model)  # Learned projection matrix for the multi-head output\n",
        "\n",
        "    def reshape_tensor(self, x, heads, flag):\n",
        "        if flag:\n",
        "            # Tensor shape after reshaping and transposing: (batch_size, heads, seq_length, -1)\n",
        "            x = reshape(x, shape=(shape(x)[0], shape(x)[1], heads, -1))\n",
        "            x = transpose(x, perm=(0, 2, 1, 3))\n",
        "        else:\n",
        "            # Reverting the reshaping and transposing operations: (batch_size, seq_length, d_k)\n",
        "            x = transpose(x, perm=(0, 2, 1, 3))\n",
        "            x = reshape(x, shape=(shape(x)[0], shape(x)[1], self.d_k))\n",
        "        return x\n",
        "\n",
        "    def call(self, queries, keys, values, mask=None):\n",
        "        # Rearrange the queries to be able to compute all heads in parallel\n",
        "        q_reshaped = self.reshape_tensor(self.W_q(queries), self.heads, True)\n",
        "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
        "\n",
        "        # Rearrange the keys to be able to compute all heads in parallel\n",
        "        k_reshaped = self.reshape_tensor(self.W_k(keys), self.heads, True)\n",
        "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
        "\n",
        "        # Rearrange the values to be able to compute all heads in parallel\n",
        "        v_reshaped = self.reshape_tensor(self.W_v(values), self.heads, True)\n",
        "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
        "\n",
        "        # Compute the multi-head attention output using the reshaped queries, keys and values\n",
        "        o_reshaped = self.attention(q_reshaped, k_reshaped, v_reshaped, self.d_k, mask)\n",
        "        # Resulting tensor shape: (batch_size, heads, input_seq_length, -1)\n",
        "\n",
        "        # Rearrange back the output into concatenated form\n",
        "        output = self.reshape_tensor(o_reshaped, self.heads, False)\n",
        "        # Resulting tensor shape: (batch_size, input_seq_length, d_v)\n",
        "\n",
        "        # Apply one final linear projection to the output to generate the multi-head attention\n",
        "        # Resulting tensor shape: (batch_size, input_seq_length, d_model)\n",
        "        return self.W_o(output)"
      ],
      "metadata": {
        "id": "oLh60z8Xp5gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionEmbeddingFixedWeights(Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, output_dim, **kwargs):\n",
        "        super(PositionEmbeddingFixedWeights, self).__init__(**kwargs)\n",
        "        word_embedding_matrix = self.get_position_encoding(vocab_size, output_dim)\n",
        "        position_embedding_matrix = self.get_position_encoding(sequence_length, output_dim)\n",
        "        self.word_embedding_layer = Embedding(\n",
        "            input_dim=vocab_size, output_dim=output_dim,\n",
        "            weights=[word_embedding_matrix],\n",
        "            trainable=False\n",
        "        )\n",
        "        self.position_embedding_layer = Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim,\n",
        "            weights=[position_embedding_matrix],\n",
        "            trainable=False\n",
        "        )\n",
        "\n",
        "    def get_position_encoding(self, seq_len, d, n=10000):\n",
        "        P = np.zeros((seq_len, d))\n",
        "        for k in range(seq_len):\n",
        "            for i in np.arange(int(d/2)):\n",
        "                denominator = np.power(n, 2*i/d)\n",
        "                P[k, 2*i] = np.sin(k/denominator)\n",
        "                P[k, 2*i+1] = np.cos(k/denominator)\n",
        "        return P\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        position_indices = tf.range(tf.shape(inputs)[-1])\n",
        "        embedded_words = self.word_embedding_layer(inputs)\n",
        "        embedded_indices = self.position_embedding_layer(position_indices)\n",
        "        return embedded_words + embedded_indices"
      ],
      "metadata": {
        "id": "YITi3f3Zqoql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LayerNormalization, Layer, Dense, ReLU, Dropout\n",
        "#from multihead_attention import MultiHeadAttention\n",
        "#from positional_encoding import PositionEmbeddingFixedWeights\n",
        "\n",
        "# Implementing the Add & Norm Layer\n",
        "class AddNormalization(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AddNormalization, self).__init__(**kwargs)\n",
        "        self.layer_norm = LayerNormalization()  # Layer normalization layer\n",
        "\n",
        "    def call(self, x, sublayer_x):\n",
        "        # The sublayer input and output need to be of the same shape to be summed\n",
        "        add = x + sublayer_x\n",
        "\n",
        "        # Apply layer normalization to the sum\n",
        "        return self.layer_norm(add)\n",
        "\n",
        "# Implementing the Feed-Forward Layer\n",
        "class FeedForward(Layer):\n",
        "    def __init__(self, d_ff, d_model, **kwargs):\n",
        "        super(FeedForward, self).__init__(**kwargs)\n",
        "        self.fully_connected1 = Dense(d_ff)  # First fully connected layer\n",
        "        self.fully_connected2 = Dense(d_model)  # Second fully connected layer\n",
        "        self.activation = ReLU()  # ReLU activation layer\n",
        "\n",
        "    def call(self, x):\n",
        "        # The input is passed into the two fully-connected layers, with a ReLU in between\n",
        "        x_fc1 = self.fully_connected1(x)\n",
        "\n",
        "        return self.fully_connected2(self.activation(x_fc1))\n",
        "\n",
        "# Implementing the Encoder Layer\n",
        "class EncoderLayer(Layer):\n",
        "    def __init__(self, h, d_k, d_v, d_model, d_ff, rate, **kwargs):\n",
        "        super(EncoderLayer, self).__init__(**kwargs)\n",
        "        self.multihead_attention = MultiHeadAttention(h, d_k, d_v, d_model)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.add_norm1 = AddNormalization()\n",
        "        self.feed_forward = FeedForward(d_ff, d_model)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "        self.add_norm2 = AddNormalization()\n",
        "\n",
        "    def call(self, x, padding_mask, training):\n",
        "        # Multi-head attention layer\n",
        "        multihead_output = self.multihead_attention(x, x, x, padding_mask)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Add in a dropout layer\n",
        "        multihead_output = self.dropout1(multihead_output, training=training)\n",
        "\n",
        "        # Followed by an Add & Norm layer\n",
        "        addnorm_output = self.add_norm1(x, multihead_output)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Followed by a fully connected layer\n",
        "        feedforward_output = self.feed_forward(addnorm_output)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "\n",
        "        # Add in another dropout layer\n",
        "        feedforward_output = self.dropout2(feedforward_output, training=training)\n",
        "\n",
        "        # Followed by another Add & Norm layer\n",
        "        return self.add_norm2(addnorm_output, feedforward_output)\n",
        "\n",
        "# Implementing the Encoder\n",
        "class Encoder(Layer):\n",
        "    def __init__(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate, **kwargs):\n",
        "        super(Encoder, self).__init__(**kwargs)\n",
        "        self.pos_encoding = PositionEmbeddingFixedWeights(sequence_length, vocab_size, d_model)\n",
        "        self.dropout = Dropout(rate)\n",
        "        self.encoder_layer = [EncoderLayer(h, d_k, d_v, d_model, d_ff, rate) for _ in range(n)]\n",
        "\n",
        "    def call(self, input_sentence, padding_mask, training):\n",
        "        # Generate the positional encoding\n",
        "        pos_encoding_output = self.pos_encoding(input_sentence)\n",
        "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
        "        print(\"asda: \" ,pos_encoding_output)\n",
        "        # Add in a dropout layer\n",
        "        x = self.dropout(pos_encoding_output, training=training)\n",
        "        print(\"dfsda :\",x);\n",
        "        # Pass on the positional encoded values to each encoder layer\n",
        "        for i, layer in enumerate(self.encoder_layer):\n",
        "            x = layer(x, padding_mask, training)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "WszVNllSlzXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3lFwlAyOeVeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import random\n",
        "import numpy as np\n",
        "from keras.layers import Embedding\n",
        "import tensorflow as tf\n",
        "\n",
        "enc_vocab_size = 20 # Vocabulary size for the encoder\n",
        "input_seq_length = 5  # Maximum length of the input sequence\n",
        "h = 8  # Number of self-attention heads\n",
        "d_k = 64  # Dimensionality of the linearly projected queries and keys\n",
        "d_v = 64  # Dimensionality of the linearly projected values\n",
        "d_ff = 2048  # Dimensionality of the inner fully connected layer\n",
        "d_model = 512  # Dimensionality of the model sub-layers' outputs\n",
        "n = 6  # Number of layers in the encoder stack\n",
        "\n",
        "batch_size = 64  # Batch size from the training process\n",
        "dropout_rate = 0.1  # Frequency of dropping the input units in the dropout layers\n",
        "\n",
        "input_seq = random.random((batch_size, input_seq_length))\n",
        "\n",
        "encoder = Encoder(enc_vocab_size, input_seq_length, h, d_k, d_v, d_model, d_ff, n, dropout_rate)\n",
        "print(encoder(input_seq, None, True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JBvuz5-mDl4",
        "outputId": "034f16c2-cb3f-47a3-fe1a-c3393294b979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "asda:  tf.Tensor(\n",
            "[[[ 0.0000000e+00  2.0000000e+00  0.0000000e+00 ...  2.0000000e+00\n",
            "    0.0000000e+00  2.0000000e+00]\n",
            "  [ 8.4147096e-01  1.5403023e+00  8.2185620e-01 ...  2.0000000e+00\n",
            "    1.0366329e-04  2.0000000e+00]\n",
            "  [ 9.0929741e-01  5.8385313e-01  9.3641472e-01 ...  2.0000000e+00\n",
            "    2.0732658e-04  2.0000000e+00]\n",
            "  [ 1.4112000e-01  1.0007501e-02  2.4508542e-01 ...  2.0000000e+00\n",
            "    3.1098988e-04  2.0000000e+00]\n",
            "  [-7.5680250e-01  3.4635639e-01 -6.5716684e-01 ...  1.9999999e+00\n",
            "    4.1465316e-04  2.0000000e+00]]\n",
            "\n",
            " [[ 0.0000000e+00  2.0000000e+00  0.0000000e+00 ...  2.0000000e+00\n",
            "    0.0000000e+00  2.0000000e+00]\n",
            "  [ 8.4147096e-01  1.5403023e+00  8.2185620e-01 ...  2.0000000e+00\n",
            "    1.0366329e-04  2.0000000e+00]\n",
            "  [ 9.0929741e-01  5.8385313e-01  9.3641472e-01 ...  2.0000000e+00\n",
            "    2.0732658e-04  2.0000000e+00]\n",
            "  [ 1.4112000e-01  1.0007501e-02  2.4508542e-01 ...  2.0000000e+00\n",
            "    3.1098988e-04  2.0000000e+00]\n",
            "  [-7.5680250e-01  3.4635639e-01 -6.5716684e-01 ...  1.9999999e+00\n",
            "    4.1465316e-04  2.0000000e+00]]\n",
            "\n",
            " [[ 0.0000000e+00  2.0000000e+00  0.0000000e+00 ...  2.0000000e+00\n",
            "    0.0000000e+00  2.0000000e+00]\n",
            "  [ 8.4147096e-01  1.5403023e+00  8.2185620e-01 ...  2.0000000e+00\n",
            "    1.0366329e-04  2.0000000e+00]\n",
            "  [ 9.0929741e-01  5.8385313e-01  9.3641472e-01 ...  2.0000000e+00\n",
            "    2.0732658e-04  2.0000000e+00]\n",
            "  [ 1.4112000e-01  1.0007501e-02  2.4508542e-01 ...  2.0000000e+00\n",
            "    3.1098988e-04  2.0000000e+00]\n",
            "  [-7.5680250e-01  3.4635639e-01 -6.5716684e-01 ...  1.9999999e+00\n",
            "    4.1465316e-04  2.0000000e+00]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.0000000e+00  2.0000000e+00  0.0000000e+00 ...  2.0000000e+00\n",
            "    0.0000000e+00  2.0000000e+00]\n",
            "  [ 8.4147096e-01  1.5403023e+00  8.2185620e-01 ...  2.0000000e+00\n",
            "    1.0366329e-04  2.0000000e+00]\n",
            "  [ 9.0929741e-01  5.8385313e-01  9.3641472e-01 ...  2.0000000e+00\n",
            "    2.0732658e-04  2.0000000e+00]\n",
            "  [ 1.4112000e-01  1.0007501e-02  2.4508542e-01 ...  2.0000000e+00\n",
            "    3.1098988e-04  2.0000000e+00]\n",
            "  [-7.5680250e-01  3.4635639e-01 -6.5716684e-01 ...  1.9999999e+00\n",
            "    4.1465316e-04  2.0000000e+00]]\n",
            "\n",
            " [[ 0.0000000e+00  2.0000000e+00  0.0000000e+00 ...  2.0000000e+00\n",
            "    0.0000000e+00  2.0000000e+00]\n",
            "  [ 8.4147096e-01  1.5403023e+00  8.2185620e-01 ...  2.0000000e+00\n",
            "    1.0366329e-04  2.0000000e+00]\n",
            "  [ 9.0929741e-01  5.8385313e-01  9.3641472e-01 ...  2.0000000e+00\n",
            "    2.0732658e-04  2.0000000e+00]\n",
            "  [ 1.4112000e-01  1.0007501e-02  2.4508542e-01 ...  2.0000000e+00\n",
            "    3.1098988e-04  2.0000000e+00]\n",
            "  [-7.5680250e-01  3.4635639e-01 -6.5716684e-01 ...  1.9999999e+00\n",
            "    4.1465316e-04  2.0000000e+00]]\n",
            "\n",
            " [[ 0.0000000e+00  2.0000000e+00  0.0000000e+00 ...  2.0000000e+00\n",
            "    0.0000000e+00  2.0000000e+00]\n",
            "  [ 8.4147096e-01  1.5403023e+00  8.2185620e-01 ...  2.0000000e+00\n",
            "    1.0366329e-04  2.0000000e+00]\n",
            "  [ 9.0929741e-01  5.8385313e-01  9.3641472e-01 ...  2.0000000e+00\n",
            "    2.0732658e-04  2.0000000e+00]\n",
            "  [ 1.4112000e-01  1.0007501e-02  2.4508542e-01 ...  2.0000000e+00\n",
            "    3.1098988e-04  2.0000000e+00]\n",
            "  [-7.5680250e-01  3.4635639e-01 -6.5716684e-01 ...  1.9999999e+00\n",
            "    4.1465316e-04  2.0000000e+00]]], shape=(64, 5, 512), dtype=float32)\n",
            "dfsda : tf.Tensor(\n",
            "[[[ 0.00000000e+00  2.22222233e+00  0.00000000e+00 ...  2.22222233e+00\n",
            "    0.00000000e+00  2.22222233e+00]\n",
            "  [ 9.34967756e-01  1.71144700e+00  9.13173616e-01 ...  2.22222233e+00\n",
            "    1.15181436e-04  2.22222233e+00]\n",
            "  [ 1.01033056e+00  0.00000000e+00  1.04046082e+00 ...  0.00000000e+00\n",
            "    2.30362872e-04  2.22222233e+00]\n",
            "  [ 1.56800017e-01  0.00000000e+00  2.72317141e-01 ...  2.22222233e+00\n",
            "    3.45544337e-04  0.00000000e+00]\n",
            "  [-8.40891719e-01  3.84840459e-01 -7.30185390e-01 ...  2.22222209e+00\n",
            "    4.60725743e-04  2.22222233e+00]]\n",
            "\n",
            " [[ 0.00000000e+00  2.22222233e+00  0.00000000e+00 ...  2.22222233e+00\n",
            "    0.00000000e+00  0.00000000e+00]\n",
            "  [ 0.00000000e+00  1.71144700e+00  9.13173616e-01 ...  2.22222233e+00\n",
            "    1.15181436e-04  2.22222233e+00]\n",
            "  [ 1.01033056e+00  6.48725748e-01  1.04046082e+00 ...  2.22222233e+00\n",
            "    2.30362872e-04  2.22222233e+00]\n",
            "  [ 1.56800017e-01  1.11194458e-02  2.72317141e-01 ...  2.22222233e+00\n",
            "    3.45544337e-04  2.22222233e+00]\n",
            "  [-8.40891719e-01  3.84840459e-01 -7.30185390e-01 ...  2.22222209e+00\n",
            "    4.60725743e-04  2.22222233e+00]]\n",
            "\n",
            " [[ 0.00000000e+00  2.22222233e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "    0.00000000e+00  2.22222233e+00]\n",
            "  [ 9.34967756e-01  1.71144700e+00  9.13173616e-01 ...  2.22222233e+00\n",
            "    1.15181436e-04  2.22222233e+00]\n",
            "  [ 1.01033056e+00  6.48725748e-01  1.04046082e+00 ...  2.22222233e+00\n",
            "    2.30362872e-04  2.22222233e+00]\n",
            "  [ 1.56800017e-01  1.11194458e-02  2.72317141e-01 ...  2.22222233e+00\n",
            "    3.45544337e-04  2.22222233e+00]\n",
            "  [-8.40891719e-01  3.84840459e-01 -7.30185390e-01 ...  2.22222209e+00\n",
            "    4.60725743e-04  2.22222233e+00]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.00000000e+00  2.22222233e+00  0.00000000e+00 ...  2.22222233e+00\n",
            "    0.00000000e+00  2.22222233e+00]\n",
            "  [ 9.34967756e-01  1.71144700e+00  9.13173616e-01 ...  2.22222233e+00\n",
            "    1.15181436e-04  2.22222233e+00]\n",
            "  [ 1.01033056e+00  6.48725748e-01  1.04046082e+00 ...  2.22222233e+00\n",
            "    2.30362872e-04  2.22222233e+00]\n",
            "  [ 0.00000000e+00  1.11194458e-02  2.72317141e-01 ...  2.22222233e+00\n",
            "    3.45544337e-04  2.22222233e+00]\n",
            "  [-8.40891719e-01  3.84840459e-01 -7.30185390e-01 ...  2.22222209e+00\n",
            "    4.60725743e-04  2.22222233e+00]]\n",
            "\n",
            " [[ 0.00000000e+00  2.22222233e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "    0.00000000e+00  2.22222233e+00]\n",
            "  [ 9.34967756e-01  1.71144700e+00  9.13173616e-01 ...  2.22222233e+00\n",
            "    0.00000000e+00  0.00000000e+00]\n",
            "  [ 0.00000000e+00  6.48725748e-01  0.00000000e+00 ...  2.22222233e+00\n",
            "    2.30362872e-04  2.22222233e+00]\n",
            "  [ 1.56800017e-01  1.11194458e-02  2.72317141e-01 ...  2.22222233e+00\n",
            "    3.45544337e-04  2.22222233e+00]\n",
            "  [-8.40891719e-01  3.84840459e-01 -7.30185390e-01 ...  0.00000000e+00\n",
            "    4.60725743e-04  0.00000000e+00]]\n",
            "\n",
            " [[ 0.00000000e+00  2.22222233e+00  0.00000000e+00 ...  2.22222233e+00\n",
            "    0.00000000e+00  2.22222233e+00]\n",
            "  [ 9.34967756e-01  1.71144700e+00  9.13173616e-01 ...  2.22222233e+00\n",
            "    1.15181436e-04  2.22222233e+00]\n",
            "  [ 0.00000000e+00  6.48725748e-01  1.04046082e+00 ...  2.22222233e+00\n",
            "    2.30362872e-04  2.22222233e+00]\n",
            "  [ 1.56800017e-01  1.11194458e-02  2.72317141e-01 ...  2.22222233e+00\n",
            "    3.45544337e-04  2.22222233e+00]\n",
            "  [-8.40891719e-01  3.84840459e-01 -7.30185390e-01 ...  2.22222209e+00\n",
            "    4.60725743e-04  2.22222233e+00]]], shape=(64, 5, 512), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[ 1.3719562   0.8587536   0.6450681  ... -1.4239169   0.73725307\n",
            "   -0.96821094]\n",
            "  [ 0.30106008  0.10522009  0.5843378  ... -1.2677894   1.484239\n",
            "    0.02511772]\n",
            "  [ 1.6181492   0.6727321  -0.37837863 ... -0.18074541  1.2787101\n",
            "   -0.7615969 ]\n",
            "  [ 1.0902464   0.65036744  0.60985035 ... -1.2243388   1.6308266\n",
            "   -1.5816872 ]\n",
            "  [ 1.0003      0.6319214  -0.58080375 ... -1.428509    1.7399458\n",
            "   -0.9997254 ]]\n",
            "\n",
            " [[ 1.1720389   1.0862365  -0.03710266 ... -1.704822    1.3663714\n",
            "    0.20813711]\n",
            "  [ 1.2456785   0.61131227  0.3422103  ... -1.270886    1.2722347\n",
            "   -1.1785042 ]\n",
            "  [ 0.8302323   1.1184415  -0.05240705 ... -0.31490114  1.5175626\n",
            "   -1.2392881 ]\n",
            "  [ 0.64697856  1.0561503  -0.3059906  ... -1.0251393   1.2383374\n",
            "   -1.4860656 ]\n",
            "  [ 0.73879826  1.0556552  -0.327273   ... -0.6499705   0.80181754\n",
            "   -1.4495683 ]]\n",
            "\n",
            " [[ 1.0482931   0.39914286  0.854847   ... -2.0073588   1.3294089\n",
            "   -0.08499774]\n",
            "  [ 1.1305851   1.1058674   0.73356164 ... -0.9999393   0.64720476\n",
            "   -0.27137637]\n",
            "  [ 1.768093    1.0460285   0.5892095  ... -0.8691938   1.1492625\n",
            "   -0.48431656]\n",
            "  [ 1.5945224   0.4582846   0.7049799  ...  0.0648938   1.6654166\n",
            "    0.91435766]\n",
            "  [ 1.2423302   0.43676782  0.34836897 ... -1.3917145   0.76264536\n",
            "   -0.20361242]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 1.7438815   0.05218213  0.41049474 ... -0.03007188  1.4134016\n",
            "    0.01851461]\n",
            "  [ 1.5361706   1.2501543  -0.16482106 ... -1.0472363   1.023679\n",
            "   -0.50234044]\n",
            "  [ 1.5612403   0.23181023  0.21569078 ... -1.6964667   0.7579298\n",
            "   -0.10846945]\n",
            "  [ 1.9594934   0.83955663 -0.0216114  ... -0.8556718  -0.02422172\n",
            "   -0.32329848]\n",
            "  [ 1.922307    1.0520296  -0.47200528 ... -1.1611954   1.2360061\n",
            "   -0.50694525]]\n",
            "\n",
            " [[ 1.8720323   1.3933841   0.3416491  ... -1.2010139   1.1842059\n",
            "   -0.33817744]\n",
            "  [ 1.2823702   1.2177796   0.51592803 ... -0.98437375  0.4615472\n",
            "   -0.17189005]\n",
            "  [ 0.58973485  0.60407877  0.44654825 ... -1.363468    1.1093006\n",
            "   -0.6694673 ]\n",
            "  [ 1.4507356   1.2467473   0.63624346 ... -1.2662406   1.1059258\n",
            "   -0.10136046]\n",
            "  [ 0.95614505  0.70291257  0.2837798  ... -2.2389517   0.6559652\n",
            "   -0.909747  ]]\n",
            "\n",
            " [[ 0.97256666  0.38319552  1.0311528  ... -0.14168756  0.7850277\n",
            "   -0.66911614]\n",
            "  [ 2.0547798   0.94920856  0.92534834 ... -0.75688136  0.32403287\n",
            "   -0.6723941 ]\n",
            "  [ 1.1826279   0.84426767  1.0384444  ... -0.42141145  0.4404968\n",
            "   -1.0737007 ]\n",
            "  [ 0.7872717   0.4229546   0.3836149  ... -1.5552368   0.72327346\n",
            "   -0.50783664]\n",
            "  [ 1.7000959   0.5079549   1.1159569  ... -0.9699152   0.058134\n",
            "   -1.5345435 ]]], shape=(64, 5, 512), dtype=float32)\n"
          ]
        }
      ]
    }
  ]
}